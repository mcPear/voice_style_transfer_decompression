Noatki AutoVC

AUTOVC works on the speech mel-spectrogram of size N-by-T, where N is the number of mel-frequency bins and T is
the number of time steps (frames).
As shown in Fig. 3(a), the input to the content encoder is the
80-dimensional mel-spectrogram of X1 concatenated with
the speaker embedding, Es(X1), at each time step. 

In our implementation, the frame rate of the
mel-spetrogram is 62.5 Hz and the sampling rate of speech
waveform is 16 kHz.

ZADANIA:
1. Wypowiedź -> mel - jaka wypowiedź, jakie parametry mel ?
2. mel -> style mebedding - TD czy TI ? jaki rozmiar, jak ?
3. Transformacja embeddingu i mel tak, żeby odpowiadało wejściu AutoVC i odpalenie

IMPROVEMENTS:
1. train style encoder on all utterances(without train/test split)
1. train style encoder in text dependent version (handles noise propably but do we need it?)

enroll_embed - mean of utterances(centroid), mean of verif_embed during test
verif_embed - all utterances of speaker and (what is important) also splitted to non silent parts
centroid embedding should be same as separate embeddings!

autovc params:
embedding - 256
mel size - 80

E2EGL default params:
embedding - 256 - but implementation has bug, should set it for tisv
mel size - 40
------
Dekompresja
Czy inny rozmiar wypowiedzi zmieni zawartość informacji o treści/stylu w embeddingu ?
Czy to będzie ten sam sposób uczenia i loss?
Można zachować już wyuczone wagi i od nich startować, albo uczyć tylko warstwę embeddingu, a resztę usztywnić.

Podczas ładowania modelu trzeba sprawdzić jaki model_num daje najmniejszy błąd.

!!@@!!Praca w dockerze gpu wymaga restartowania kernela po modyfikacji pliku i podawania wewnętrznych ścieżek kontenera

Model wyuczył się na float32(DT_FLOAT), a powinien na float16(DT_HALF), bo byłoby szybciej. Nie wiem dlaczego podczas testu graf był float16, a podczas treningu uczył się float32...
Jeśli będzie wolny feedforward na float32 to można jeszcze raz wyuczyć na float16, ale prawdopodobnie nie będzie trzeba. Dodałem funkcję printującą graf z typami zmiennych.

Batche:
enrollment - średnia z kilku
verif - pojedynczy ostatni
ale ten podział jest tylko w test
w train jest jeden batch

Split działa tak, ze dzieli na części gdzie jest głos (>20db) i wybiera pierwsze i ostatnie 180 ramek z każdej części.
Ciekawe czemu nie wszystkie ?

Jest problem z długością spektrogramu. Nie wiem czy to zależy od sampling rate, ale w autoVC są dużo krótze te spektrogramy. Trzeba wziąć wypowiedź i spektogram i rozkminić jak oni zamieniają, a potem może będzie trzeba wyuczyć na takich parametrach...

------------Voice Conversion, Chou et al.-------------
W kroku pierwszym uczymy się kodować treść ucząc autokodera i minimalizujac prawdopodobieństwo, że wypowiedź należy do tego mówcy, żeby uniezależnić embedding od mówcy. Ale nie wiem jak jest liczone to prawdopodobieństwo.
Można zaatakować na większym zbiorze.


-----
#target
processing 225
9/231 too short (<128)
processing 226
1/356 too short (<128)
processing 227
1/389 too short (<128)
processing 228
8/366 too short (<128)
processing 229
38/379 too short (<128)
processing 230
5/397 too short (<128)
processing 231
55/456 too short (<128)
processing 232
54/412 too short (<128)
processing 233
8/372 too short (<128)
processing 236
39/492 too short (<128)
processing 239
11/503 too short (<128)
processing 240
25/377 too short (<128)
processing 243
5/393 too short (<128)
processing 244
0/420 too short (<128)
processing 250
37/481 too short (<128)
processing 254
52/397 too short (<128)
processing 256
0/319 too short (<128)
processing 257
105/434 too short (<128)
processing 258
56/414 too short (<128)
processing 259
4/481 too short (<128)
processing 267
14/417 too short (<128)
processing 268
0/406 too short (<128)
processing 269
19/396 too short (<128)
processing 270
22/462 too short (<128)
processing 273
17/433 too short (<128)
processing 274
3/466 too short (<128)
processing 276
6/462 too short (<128)
processing 277
49/459 too short (<128)
processing 278
6/409 too short (<128)
processing 279
18/405 too short (<128)
processing 282
7/368 too short (<128)
processing 286
8/468 too short (<128)
processing 287
2/424 too short (<128)

#8bit
processing 225
9/231 too short (<128)
processing 226
1/356 too short (<128)
processing 227
1/389 too short (<128)
processing 228
6/366 too short (<128)
processing 229
30/379 too short (<128)
processing 230
5/397 too short (<128)
processing 231
40/456 too short (<128)
processing 232
48/412 too short (<128)
processing 233
5/372 too short (<128)
processing 236
31/492 too short (<128)
processing 239
8/503 too short (<128)
processing 240
19/377 too short (<128)
processing 243
5/393 too short (<128)
processing 244
0/420 too short (<128)
processing 250
29/481 too short (<128)
processing 254
39/397 too short (<128)
processing 256
0/319 too short (<128)
processing 257
92/434 too short (<128)
processing 258
53/414 too short (<128)
processing 259
3/481 too short (<128)
processing 267
7/417 too short (<128)
processing 268
0/406 too short (<128)
processing 269
19/396 too short (<128)
processing 270
19/462 too short (<128)
processing 273
12/433 too short (<128)
processing 274
1/466 too short (<128)
processing 276
5/462 too short (<128)
processing 277
45/459 too short (<128)
processing 278
5/409 too short (<128)
processing 279
16/405 too short (<128)
processing 282
7/368 too short (<128)
processing 286
4/468 too short (<128)
processing 287
2/424 too short (<128)
