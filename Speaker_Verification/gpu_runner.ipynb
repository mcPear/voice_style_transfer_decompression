{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Session\n",
      "embedded size:  (20, 256)\n",
      "similarity matrix size:  (20, 4)\n",
      "total variables : 4776962\n",
      "(iter : 100) loss: 17.3487\n",
      "(iter : 200) loss: 13.2115\n",
      "(iter : 300) loss: 11.9221\n",
      "(iter : 400) loss: 10.3166\n",
      "(iter : 500) loss: 8.9830\n",
      "(iter : 600) loss: 8.9961\n",
      "(iter : 700) loss: 7.1087\n",
      "(iter : 800) loss: 7.0661\n",
      "(iter : 900) loss: 7.4436\n",
      "(iter : 1000) loss: 6.4320\n",
      "(iter : 1100) loss: 5.7710\n",
      "(iter : 1200) loss: 5.4419\n",
      "(iter : 1300) loss: 5.8842\n",
      "(iter : 1400) loss: 4.4182\n",
      "(iter : 1500) loss: 4.0501\n",
      "(iter : 1600) loss: 4.4670\n",
      "(iter : 1700) loss: 3.9264\n",
      "(iter : 1800) loss: 3.7656\n",
      "(iter : 1900) loss: 3.6360\n",
      "(iter : 2000) loss: 3.0702\n",
      "(iter : 2100) loss: 3.2591\n",
      "(iter : 2200) loss: 2.8217\n",
      "(iter : 2300) loss: 3.5105\n",
      "(iter : 2400) loss: 3.3590\n",
      "(iter : 2500) loss: 2.4626\n",
      "(iter : 2600) loss: 2.7144\n",
      "(iter : 2700) loss: 2.8135\n",
      "(iter : 2800) loss: 3.0741\n",
      "(iter : 2900) loss: 2.3017\n",
      "(iter : 3000) loss: 2.5850\n",
      "(iter : 3100) loss: 2.0103\n",
      "(iter : 3200) loss: 1.8875\n",
      "(iter : 3300) loss: 1.9243\n",
      "(iter : 3400) loss: 2.4561\n",
      "(iter : 3500) loss: 1.7527\n",
      "(iter : 3600) loss: 1.5902\n",
      "(iter : 3700) loss: 1.9754\n",
      "(iter : 3800) loss: 1.8659\n",
      "(iter : 3900) loss: 1.6199\n",
      "(iter : 4000) loss: 1.6832\n",
      "(iter : 4100) loss: 1.4790\n",
      "(iter : 4200) loss: 1.6401\n",
      "(iter : 4300) loss: 1.8047\n",
      "(iter : 4400) loss: 1.6224\n",
      "(iter : 4500) loss: 1.5613\n",
      "(iter : 4600) loss: 1.4082\n",
      "(iter : 4700) loss: 1.9055\n",
      "(iter : 4800) loss: 1.4462\n",
      "(iter : 4900) loss: 1.4665\n",
      "(iter : 5000) loss: 1.3094\n",
      "(iter : 5100) loss: 1.3912\n",
      "(iter : 5200) loss: 1.8213\n",
      "(iter : 5300) loss: 1.3279\n",
      "(iter : 5400) loss: 1.5035\n",
      "(iter : 5500) loss: 1.3442\n",
      "(iter : 5600) loss: 1.0651\n",
      "(iter : 5700) loss: 1.2707\n",
      "(iter : 5800) loss: 1.1866\n",
      "(iter : 5900) loss: 1.1781\n",
      "(iter : 6000) loss: 1.2999\n",
      "(iter : 6100) loss: 1.1348\n",
      "(iter : 6200) loss: 1.2145\n",
      "(iter : 6300) loss: 1.2183\n",
      "(iter : 6400) loss: 0.8832\n",
      "(iter : 6500) loss: 1.0745\n",
      "(iter : 6600) loss: 0.9165\n",
      "(iter : 6700) loss: 0.9771\n",
      "(iter : 6800) loss: 0.8618\n",
      "(iter : 6900) loss: 1.1411\n",
      "(iter : 7000) loss: 1.1680\n",
      "(iter : 7100) loss: 0.9333\n",
      "(iter : 7200) loss: 1.1332\n",
      "(iter : 7300) loss: 1.2075\n",
      "(iter : 7400) loss: 0.9035\n",
      "(iter : 7500) loss: 1.1012\n",
      "(iter : 7600) loss: 0.9347\n",
      "(iter : 7700) loss: 0.9711\n",
      "(iter : 7800) loss: 0.8871\n",
      "(iter : 7900) loss: 0.6972\n",
      "(iter : 8000) loss: 1.0653\n",
      "(iter : 8100) loss: 1.1076\n",
      "(iter : 8200) loss: 1.0126\n",
      "(iter : 8300) loss: 1.2713\n",
      "(iter : 8400) loss: 0.7382\n",
      "(iter : 8500) loss: 0.9904\n",
      "(iter : 8600) loss: 0.6247\n",
      "(iter : 8700) loss: 0.9255\n",
      "(iter : 8800) loss: 0.9144\n",
      "(iter : 8900) loss: 0.6638\n",
      "(iter : 9000) loss: 0.6756\n",
      "(iter : 9100) loss: 0.8296\n",
      "(iter : 9200) loss: 0.8770\n",
      "(iter : 9300) loss: 0.8380\n",
      "(iter : 9400) loss: 0.5374\n",
      "(iter : 9500) loss: 0.9579\n",
      "(iter : 9600) loss: 0.7321\n",
      "(iter : 9700) loss: 1.0112\n",
      "(iter : 9800) loss: 1.0002\n",
      "(iter : 9900) loss: 0.6610\n",
      "(iter : 10000) loss: 0.6430\n",
      "learning rate is decayed! current lr :  0.005\n",
      "model is saved!\n",
      "(iter : 10100) loss: 0.4573\n",
      "(iter : 10200) loss: 0.3157\n",
      "(iter : 10300) loss: 0.2486\n",
      "(iter : 10400) loss: 0.3538\n",
      "(iter : 10500) loss: 0.3285\n",
      "(iter : 10600) loss: 0.3185\n",
      "(iter : 10700) loss: 0.3736\n",
      "(iter : 10800) loss: 0.1702\n",
      "(iter : 10900) loss: 0.2860\n",
      "(iter : 11000) loss: 0.3187\n",
      "(iter : 11100) loss: 0.2671\n",
      "(iter : 11200) loss: 0.3115\n",
      "(iter : 11300) loss: 0.3393\n",
      "(iter : 11400) loss: 0.2521\n",
      "(iter : 11500) loss: 0.3206\n",
      "(iter : 11600) loss: 0.3649\n",
      "(iter : 11700) loss: 0.4235\n",
      "(iter : 11800) loss: 0.3512\n",
      "(iter : 11900) loss: 0.4912\n",
      "(iter : 12000) loss: 0.3142\n",
      "(iter : 12100) loss: 0.2872\n",
      "(iter : 12200) loss: 0.1937\n",
      "(iter : 12300) loss: 0.4205\n",
      "(iter : 12400) loss: 0.2693\n",
      "(iter : 12500) loss: 0.3533\n",
      "(iter : 12600) loss: 0.3274\n",
      "(iter : 12700) loss: 0.3964\n",
      "(iter : 12800) loss: 0.2518\n",
      "(iter : 12900) loss: 0.1595\n",
      "(iter : 13000) loss: 0.4027\n",
      "(iter : 13100) loss: 0.2250\n",
      "(iter : 13200) loss: 0.2567\n",
      "(iter : 13300) loss: 0.4587\n",
      "(iter : 13400) loss: 0.3797\n",
      "(iter : 13500) loss: 0.1960\n",
      "(iter : 13600) loss: 0.4283\n",
      "(iter : 13700) loss: 0.3890\n",
      "(iter : 13800) loss: 0.2669\n",
      "(iter : 13900) loss: 0.2986\n",
      "(iter : 14000) loss: 0.4009\n",
      "(iter : 14100) loss: 0.1824\n",
      "(iter : 14200) loss: 0.3952\n",
      "(iter : 14300) loss: 0.3251\n",
      "(iter : 14400) loss: 0.1558\n",
      "(iter : 14500) loss: 0.5953\n",
      "(iter : 14600) loss: 0.3317\n",
      "(iter : 14700) loss: 0.1853\n",
      "(iter : 14800) loss: 0.1491\n",
      "(iter : 14900) loss: 0.3773\n",
      "(iter : 15000) loss: 0.1298\n",
      "(iter : 15100) loss: 0.2855\n",
      "(iter : 15200) loss: 0.2972\n",
      "(iter : 15300) loss: 0.1174\n",
      "(iter : 15400) loss: 0.3207\n",
      "(iter : 15500) loss: 0.1161\n",
      "(iter : 15600) loss: 0.1876\n",
      "(iter : 15700) loss: 0.2734\n",
      "(iter : 15800) loss: 0.3048\n",
      "(iter : 15900) loss: 0.3774\n",
      "(iter : 16000) loss: 0.1931\n",
      "(iter : 16100) loss: 0.2487\n",
      "(iter : 16200) loss: 0.2244\n",
      "(iter : 16300) loss: 0.3594\n",
      "(iter : 16400) loss: 0.1757\n",
      "(iter : 16500) loss: 0.1114\n",
      "(iter : 16600) loss: 0.2249\n",
      "(iter : 16700) loss: 0.3161\n",
      "(iter : 16800) loss: 0.2188\n",
      "(iter : 16900) loss: 0.2667\n",
      "(iter : 17000) loss: 0.3078\n",
      "(iter : 17100) loss: 0.1809\n",
      "(iter : 17200) loss: 0.1908\n",
      "(iter : 17300) loss: 0.2539\n",
      "(iter : 17400) loss: 0.2138\n",
      "(iter : 17500) loss: 0.2115\n",
      "(iter : 17600) loss: 0.1854\n",
      "(iter : 17700) loss: 0.2970\n",
      "(iter : 17800) loss: 0.1249\n",
      "(iter : 17900) loss: 0.1627\n",
      "(iter : 18000) loss: 0.3547\n",
      "(iter : 18100) loss: 0.1944\n",
      "(iter : 18200) loss: 0.2034\n",
      "(iter : 18300) loss: 0.1581\n",
      "(iter : 18400) loss: 0.2367\n",
      "(iter : 18500) loss: 0.2507\n",
      "(iter : 18600) loss: 0.3547\n",
      "(iter : 18700) loss: 0.0963\n",
      "(iter : 18800) loss: 0.2386\n",
      "(iter : 18900) loss: 0.1412\n",
      "(iter : 19000) loss: 0.3365\n",
      "(iter : 19100) loss: 0.2723\n",
      "(iter : 19200) loss: 0.1802\n",
      "(iter : 19300) loss: 0.2264\n",
      "(iter : 19400) loss: 0.2802\n",
      "(iter : 19500) loss: 0.3086\n",
      "(iter : 19600) loss: 0.1142\n",
      "(iter : 19700) loss: 0.3499\n",
      "(iter : 19800) loss: 0.1863\n",
      "(iter : 19900) loss: 0.1070\n",
      "(iter : 20000) loss: 0.1462\n",
      "learning rate is decayed! current lr :  0.0025\n",
      "model is saved!\n",
      "(iter : 20100) loss: 0.0974\n",
      "(iter : 20200) loss: 0.0525\n",
      "(iter : 20300) loss: 0.0813\n",
      "(iter : 20400) loss: 0.0928\n",
      "(iter : 20500) loss: 0.1587\n",
      "(iter : 20600) loss: 0.0513\n",
      "(iter : 20700) loss: 0.1531\n",
      "(iter : 20800) loss: 0.0854\n",
      "(iter : 20900) loss: 0.0940\n",
      "(iter : 21000) loss: 0.1410\n",
      "(iter : 21100) loss: 0.1399\n",
      "(iter : 21200) loss: 0.0155\n",
      "(iter : 21300) loss: 0.0721\n",
      "(iter : 21400) loss: 0.0794\n",
      "(iter : 21500) loss: 0.1081\n",
      "(iter : 21600) loss: 0.0377\n",
      "(iter : 21700) loss: 0.0723\n",
      "(iter : 21800) loss: 0.1136\n",
      "(iter : 21900) loss: 0.0226\n",
      "(iter : 22000) loss: 0.0326\n",
      "(iter : 22100) loss: 0.0639\n",
      "(iter : 22200) loss: 0.0786\n",
      "(iter : 22300) loss: 0.0695\n",
      "(iter : 22400) loss: 0.1294\n",
      "(iter : 22500) loss: 0.1040\n",
      "(iter : 22600) loss: 0.1441\n",
      "(iter : 22700) loss: 0.1499\n",
      "(iter : 22800) loss: 0.0904\n",
      "(iter : 22900) loss: 0.1103\n",
      "(iter : 23000) loss: 0.0727\n",
      "(iter : 23100) loss: 0.0755\n",
      "(iter : 23200) loss: 0.0732\n",
      "(iter : 23300) loss: 0.0903\n",
      "(iter : 23400) loss: 0.0508\n",
      "(iter : 23500) loss: 0.1153\n",
      "(iter : 23600) loss: 0.2251\n",
      "(iter : 23700) loss: 0.1097\n",
      "(iter : 23800) loss: 0.0714\n",
      "(iter : 23900) loss: 0.1126\n",
      "(iter : 24000) loss: 0.0847\n",
      "(iter : 24100) loss: 0.0749\n",
      "(iter : 24200) loss: 0.0897\n",
      "(iter : 24300) loss: 0.1600\n",
      "(iter : 24400) loss: 0.0389\n",
      "(iter : 24500) loss: 0.1594\n",
      "(iter : 24600) loss: 0.0870\n",
      "(iter : 24700) loss: 0.1017\n",
      "(iter : 24800) loss: 0.0836\n",
      "(iter : 24900) loss: 0.0203\n",
      "(iter : 25000) loss: 0.0703\n",
      "(iter : 25100) loss: 0.0381\n",
      "(iter : 25200) loss: 0.1418\n",
      "(iter : 25300) loss: 0.1230\n",
      "(iter : 25400) loss: 0.0636\n",
      "(iter : 25500) loss: 0.1071\n",
      "(iter : 25600) loss: 0.1101\n",
      "(iter : 25700) loss: 0.0815\n",
      "(iter : 25800) loss: 0.0500\n",
      "(iter : 25900) loss: 0.0340\n",
      "(iter : 26000) loss: 0.1151\n",
      "(iter : 26100) loss: 0.0422\n",
      "(iter : 26200) loss: 0.0590\n",
      "(iter : 26300) loss: 0.1058\n",
      "(iter : 26400) loss: 0.0655\n",
      "(iter : 26500) loss: 0.1449\n",
      "(iter : 26600) loss: 0.0472\n",
      "(iter : 26700) loss: 0.0166\n",
      "(iter : 26800) loss: 0.0680\n",
      "(iter : 26900) loss: 0.0639\n",
      "(iter : 27000) loss: 0.0532\n",
      "(iter : 27100) loss: 0.0660\n",
      "(iter : 27200) loss: 0.1735\n",
      "(iter : 27300) loss: 0.0634\n",
      "(iter : 27400) loss: 0.0279\n",
      "(iter : 27500) loss: 0.0180\n",
      "(iter : 27600) loss: 0.0797\n",
      "(iter : 27700) loss: 0.0344\n",
      "(iter : 27800) loss: 0.0415\n",
      "(iter : 27900) loss: 0.0200\n",
      "(iter : 28000) loss: 0.0751\n",
      "(iter : 28100) loss: 0.1368\n",
      "(iter : 28200) loss: 0.0890\n",
      "(iter : 28300) loss: 0.0878\n",
      "(iter : 28400) loss: 0.0276\n",
      "(iter : 28500) loss: 0.0691\n",
      "(iter : 28600) loss: 0.0784\n",
      "(iter : 28700) loss: 0.0343\n",
      "(iter : 28800) loss: 0.0581\n",
      "(iter : 28900) loss: 0.1370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iter : 29000) loss: 0.0863\n",
      "(iter : 29100) loss: 0.1497\n",
      "(iter : 29200) loss: 0.0167\n",
      "(iter : 29300) loss: 0.0961\n",
      "(iter : 29400) loss: 0.0541\n",
      "(iter : 29500) loss: 0.0882\n",
      "(iter : 29600) loss: 0.1595\n",
      "(iter : 29700) loss: 0.0418\n",
      "(iter : 29800) loss: 0.0796\n",
      "(iter : 29900) loss: 0.1537\n",
      "(iter : 30000) loss: 0.0747\n",
      "learning rate is decayed! current lr :  0.00125\n",
      "model is saved!\n",
      "(iter : 30100) loss: 0.0533\n",
      "(iter : 30200) loss: 0.0157\n",
      "(iter : 30300) loss: 0.0112\n",
      "(iter : 30400) loss: 0.0237\n",
      "(iter : 30500) loss: 0.0596\n",
      "(iter : 30600) loss: 0.0269\n",
      "(iter : 30700) loss: 0.0422\n",
      "(iter : 30800) loss: 0.0738\n",
      "(iter : 30900) loss: 0.0472\n",
      "(iter : 31000) loss: 0.0289\n",
      "(iter : 31100) loss: 0.0354\n",
      "(iter : 31200) loss: 0.0859\n",
      "(iter : 31300) loss: 0.0640\n",
      "(iter : 31400) loss: 0.0259\n",
      "(iter : 31500) loss: 0.0133\n",
      "(iter : 31600) loss: 0.1477\n",
      "(iter : 31700) loss: 0.0302\n",
      "(iter : 31800) loss: 0.0094\n",
      "(iter : 31900) loss: 0.0254\n",
      "(iter : 32000) loss: 0.0782\n",
      "(iter : 32100) loss: 0.0444\n",
      "(iter : 32200) loss: 0.0518\n",
      "(iter : 32300) loss: 0.0667\n",
      "(iter : 32400) loss: 0.0343\n",
      "(iter : 32500) loss: 0.0090\n",
      "(iter : 32600) loss: 0.0188\n",
      "(iter : 32700) loss: 0.0125\n",
      "(iter : 32800) loss: 0.0581\n",
      "(iter : 32900) loss: 0.0308\n",
      "(iter : 33000) loss: 0.0617\n",
      "(iter : 33100) loss: 0.0793\n",
      "(iter : 33200) loss: 0.0661\n",
      "(iter : 33300) loss: 0.0519\n",
      "(iter : 33400) loss: 0.0917\n",
      "(iter : 33500) loss: 0.0197\n",
      "(iter : 33600) loss: 0.0231\n",
      "(iter : 33700) loss: 0.0219\n",
      "(iter : 33800) loss: 0.0661\n",
      "(iter : 33900) loss: 0.0088\n",
      "(iter : 34000) loss: 0.0792\n",
      "(iter : 34100) loss: 0.0153\n",
      "(iter : 34200) loss: 0.0113\n",
      "(iter : 34300) loss: 0.0125\n",
      "(iter : 34400) loss: 0.0566\n",
      "(iter : 34500) loss: 0.0157\n",
      "(iter : 34600) loss: 0.0120\n",
      "(iter : 34700) loss: 0.0621\n",
      "(iter : 34800) loss: 0.0635\n",
      "(iter : 34900) loss: 0.0391\n",
      "(iter : 35000) loss: 0.0156\n",
      "(iter : 35100) loss: 0.0312\n",
      "(iter : 35200) loss: 0.0127\n",
      "(iter : 35300) loss: 0.0128\n",
      "(iter : 35400) loss: 0.0099\n",
      "(iter : 35500) loss: 0.0269\n",
      "(iter : 35600) loss: 0.0543\n",
      "(iter : 35700) loss: 0.0372\n",
      "(iter : 35800) loss: 0.0710\n",
      "(iter : 35900) loss: 0.0880\n",
      "(iter : 36000) loss: 0.0484\n",
      "(iter : 36100) loss: 0.0586\n",
      "(iter : 36200) loss: 0.0413\n",
      "(iter : 36300) loss: 0.0572\n",
      "(iter : 36400) loss: 0.0329\n",
      "(iter : 36500) loss: 0.0429\n",
      "(iter : 36600) loss: 0.0230\n",
      "(iter : 36700) loss: 0.0488\n",
      "(iter : 36800) loss: 0.0112\n",
      "(iter : 36900) loss: 0.0742\n",
      "(iter : 37000) loss: 0.0336\n",
      "(iter : 37100) loss: 0.0301\n",
      "(iter : 37200) loss: 0.0392\n",
      "(iter : 37300) loss: 0.0085\n",
      "(iter : 37400) loss: 0.0303\n",
      "(iter : 37500) loss: 0.0563\n",
      "(iter : 37600) loss: 0.0710\n",
      "(iter : 37700) loss: 0.0990\n",
      "(iter : 37800) loss: 0.0366\n",
      "(iter : 37900) loss: 0.0088\n",
      "(iter : 38000) loss: 0.0491\n",
      "(iter : 38100) loss: 0.0184\n",
      "(iter : 38200) loss: 0.0259\n",
      "(iter : 38300) loss: 0.0251\n",
      "(iter : 38400) loss: 0.0818\n",
      "(iter : 38500) loss: 0.0098\n",
      "(iter : 38600) loss: 0.0195\n",
      "(iter : 38700) loss: 0.0316\n",
      "(iter : 38800) loss: 0.0754\n",
      "(iter : 38900) loss: 0.0441\n",
      "(iter : 39000) loss: 0.0077\n",
      "(iter : 39100) loss: 0.0294\n",
      "(iter : 39200) loss: 0.0183\n",
      "(iter : 39300) loss: 0.0463\n",
      "(iter : 39400) loss: 0.0803\n",
      "(iter : 39500) loss: 0.0399\n",
      "(iter : 39600) loss: 0.0085\n",
      "(iter : 39700) loss: 0.0598\n",
      "(iter : 39800) loss: 0.0326\n",
      "(iter : 39900) loss: 0.0734\n",
      "(iter : 40000) loss: 0.0142\n",
      "learning rate is decayed! current lr :  0.000625\n",
      "model is saved!\n",
      "(iter : 40100) loss: 0.0348\n",
      "(iter : 40200) loss: 0.0468\n",
      "(iter : 40300) loss: 0.0091\n",
      "(iter : 40400) loss: 0.0199\n",
      "(iter : 40500) loss: 0.0635\n",
      "(iter : 40600) loss: 0.0070\n",
      "(iter : 40700) loss: 0.0340\n",
      "(iter : 40800) loss: 0.0328\n",
      "(iter : 40900) loss: 0.0531\n",
      "(iter : 41000) loss: 0.0143\n",
      "(iter : 41100) loss: 0.0088\n",
      "(iter : 41200) loss: 0.0198\n",
      "(iter : 41300) loss: 0.0170\n",
      "(iter : 41400) loss: 0.1144\n",
      "(iter : 41500) loss: 0.0356\n",
      "(iter : 41600) loss: 0.0325\n",
      "(iter : 41700) loss: 0.0246\n",
      "(iter : 41800) loss: 0.0285\n",
      "(iter : 41900) loss: 0.0090\n",
      "(iter : 42000) loss: 0.0068\n",
      "(iter : 42100) loss: 0.0065\n",
      "(iter : 42200) loss: 0.0451\n",
      "(iter : 42300) loss: 0.0190\n",
      "(iter : 42400) loss: 0.0270\n",
      "(iter : 42500) loss: 0.0718\n",
      "(iter : 42600) loss: 0.0212\n",
      "(iter : 42700) loss: 0.0091\n",
      "(iter : 42800) loss: 0.0064\n",
      "(iter : 42900) loss: 0.0289\n",
      "(iter : 43000) loss: 0.0155\n",
      "(iter : 43100) loss: 0.0120\n",
      "(iter : 43200) loss: 0.0272\n",
      "(iter : 43300) loss: 0.0063\n",
      "(iter : 43400) loss: 0.0184\n",
      "(iter : 43500) loss: 0.0072\n",
      "(iter : 43600) loss: 0.0413\n",
      "(iter : 43700) loss: 0.0074\n",
      "(iter : 43800) loss: 0.0091\n",
      "(iter : 43900) loss: 0.0128\n",
      "(iter : 44000) loss: 0.0252\n",
      "(iter : 44100) loss: 0.0606\n",
      "(iter : 44200) loss: 0.0203\n",
      "(iter : 44300) loss: 0.0064\n",
      "(iter : 44400) loss: 0.0183\n",
      "(iter : 44500) loss: 0.0555\n",
      "(iter : 44600) loss: 0.0671\n",
      "(iter : 44700) loss: 0.0355\n",
      "(iter : 44800) loss: 0.0938\n",
      "(iter : 44900) loss: 0.0234\n",
      "(iter : 45000) loss: 0.0127\n",
      "(iter : 45100) loss: 0.0093\n",
      "(iter : 45200) loss: 0.0101\n",
      "(iter : 45300) loss: 0.0146\n",
      "(iter : 45400) loss: 0.0086\n",
      "(iter : 45500) loss: 0.0390\n",
      "(iter : 45600) loss: 0.0074\n",
      "(iter : 45700) loss: 0.0459\n",
      "(iter : 45800) loss: 0.0071\n",
      "(iter : 45900) loss: 0.0071\n",
      "(iter : 46000) loss: 0.0546\n",
      "(iter : 46100) loss: 0.0675\n",
      "(iter : 46200) loss: 0.0467\n",
      "(iter : 46300) loss: 0.0078\n",
      "(iter : 46400) loss: 0.0063\n",
      "(iter : 46500) loss: 0.0082\n",
      "(iter : 46600) loss: 0.0215\n",
      "(iter : 46700) loss: 0.0061\n",
      "(iter : 46800) loss: 0.0161\n",
      "(iter : 46900) loss: 0.0124\n",
      "(iter : 47000) loss: 0.0131\n",
      "(iter : 47100) loss: 0.0587\n",
      "(iter : 47200) loss: 0.0183\n",
      "(iter : 47300) loss: 0.0155\n",
      "(iter : 47400) loss: 0.0085\n",
      "(iter : 47500) loss: 0.0275\n",
      "(iter : 47600) loss: 0.0124\n",
      "(iter : 47700) loss: 0.0194\n",
      "(iter : 47800) loss: 0.0418\n",
      "(iter : 47900) loss: 0.0095\n",
      "(iter : 48000) loss: 0.0526\n",
      "(iter : 48100) loss: 0.0157\n",
      "(iter : 48200) loss: 0.0162\n",
      "(iter : 48300) loss: 0.0070\n",
      "(iter : 48400) loss: 0.0254\n",
      "(iter : 48500) loss: 0.0198\n",
      "(iter : 48600) loss: 0.0137\n",
      "(iter : 48700) loss: 0.0138\n",
      "(iter : 48800) loss: 0.0067\n",
      "(iter : 48900) loss: 0.0130\n",
      "(iter : 49000) loss: 0.0316\n",
      "(iter : 49100) loss: 0.0105\n",
      "(iter : 49200) loss: 0.0181\n",
      "(iter : 49300) loss: 0.0445\n",
      "(iter : 49400) loss: 0.0531\n",
      "(iter : 49500) loss: 0.0386\n",
      "(iter : 49600) loss: 0.1055\n",
      "(iter : 49700) loss: 0.0082\n",
      "(iter : 49800) loss: 0.0077\n",
      "(iter : 49900) loss: 0.0091\n",
      "(iter : 50000) loss: 0.0163\n",
      "learning rate is decayed! current lr :  0.0003125\n",
      "model is saved!\n",
      "(iter : 50100) loss: 0.0113\n",
      "(iter : 50200) loss: 0.0070\n",
      "(iter : 50300) loss: 0.0321\n",
      "(iter : 50400) loss: 0.0061\n",
      "(iter : 50500) loss: 0.0078\n",
      "(iter : 50600) loss: 0.0558\n",
      "(iter : 50700) loss: 0.0075\n",
      "(iter : 50800) loss: 0.0421\n",
      "(iter : 50900) loss: 0.0238\n",
      "(iter : 51000) loss: 0.0067\n",
      "(iter : 51100) loss: 0.0388\n",
      "(iter : 51200) loss: 0.0300\n",
      "(iter : 51300) loss: 0.0116\n",
      "(iter : 51400) loss: 0.0180\n",
      "(iter : 51500) loss: 0.0628\n",
      "(iter : 51600) loss: 0.0064\n",
      "(iter : 51700) loss: 0.0081\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from model import train, test\n",
    "from configuration import get_config\n",
    "import errno    \n",
    "import os\n",
    "\n",
    "#RTX float16 setup:\n",
    "tf.compat.v1.keras.backend.set_floatx('float16')\n",
    "tf.compat.v1.keras.backend.set_epsilon(1e-4) \n",
    "\n",
    "config = get_config()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "print(\"\\nTraining Session\")\n",
    "mkdir_p(config.model_path)\n",
    "train(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "Cuda compilation tools, release 10.0, V10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(M=5, N=4, beta1=0.5, beta2=0.9, comment='', hidden=768, hop=0.01, iteration=100000, loss='softmax', lr=0.01, mel_size=80, model_num=6, model_path='./tisv_model', nfft=512, noise_filenum=16, noise_path='./noise', num_layer=3, optim='sgd', proj=256, restore=False, sr=8000, tdsv=False, tdsv_frame=80, test_path='./test_tisv', tisv_frame=180, train=True, train_path='./train_tisv', window=0.025)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"main.py\", line 3, in <module>\r\n",
      "    from model import train, test\r\n",
      "  File \"/tf/notebooks/SKAJPAI/voice_style_transfer/Speaker_Verification/model.py\", line 7, in <module>\r\n",
      "    from tensorflow_addons import rnn\r\n",
      "ModuleNotFoundError: No module named 'tensorflow_addons'\r\n"
     ]
    }
   ],
   "source": [
    "!python3.6 main.py --train=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 817kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow_addons) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.30.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.1.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.24.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.17.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.9.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow_addons) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (41.2.0)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.6.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3.6 -m pip install tensorflow_addons\n",
    "#!apt install libsndfile1 --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
