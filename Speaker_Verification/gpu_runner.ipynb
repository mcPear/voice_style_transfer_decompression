{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Session\n",
      "embedded size:  (20, 256)\n",
      "similarity matrix size:  (20, 4)\n",
      "total variables : 4776962\n",
      "(iter : 100) loss: 17.3487\n",
      "(iter : 200) loss: 13.2115\n",
      "(iter : 300) loss: 11.9221\n",
      "(iter : 400) loss: 10.3166\n",
      "(iter : 500) loss: 8.9830\n",
      "(iter : 600) loss: 8.9961\n",
      "(iter : 700) loss: 7.1087\n",
      "(iter : 800) loss: 7.0661\n",
      "(iter : 900) loss: 7.4436\n",
      "(iter : 1000) loss: 6.4320\n",
      "(iter : 1100) loss: 5.7710\n",
      "(iter : 1200) loss: 5.4419\n",
      "(iter : 1300) loss: 5.8842\n",
      "(iter : 1400) loss: 4.4182\n",
      "(iter : 1500) loss: 4.0501\n",
      "(iter : 1600) loss: 4.4670\n",
      "(iter : 1700) loss: 3.9264\n",
      "(iter : 1800) loss: 3.7656\n",
      "(iter : 1900) loss: 3.6360\n",
      "(iter : 2000) loss: 3.0702\n",
      "(iter : 2100) loss: 3.2591\n",
      "(iter : 2200) loss: 2.8217\n",
      "(iter : 2300) loss: 3.5105\n",
      "(iter : 2400) loss: 3.3590\n",
      "(iter : 2500) loss: 2.4626\n",
      "(iter : 2600) loss: 2.7144\n",
      "(iter : 2700) loss: 2.8135\n",
      "(iter : 2800) loss: 3.0741\n",
      "(iter : 2900) loss: 2.3017\n",
      "(iter : 3000) loss: 2.5850\n",
      "(iter : 3100) loss: 2.0103\n",
      "(iter : 3200) loss: 1.8875\n",
      "(iter : 3300) loss: 1.9243\n",
      "(iter : 3400) loss: 2.4561\n",
      "(iter : 3500) loss: 1.7527\n",
      "(iter : 3600) loss: 1.5902\n",
      "(iter : 3700) loss: 1.9754\n",
      "(iter : 3800) loss: 1.8659\n",
      "(iter : 3900) loss: 1.6199\n",
      "(iter : 4000) loss: 1.6832\n",
      "(iter : 4100) loss: 1.4790\n",
      "(iter : 4200) loss: 1.6401\n",
      "(iter : 4300) loss: 1.8047\n",
      "(iter : 4400) loss: 1.6224\n",
      "(iter : 4500) loss: 1.5613\n",
      "(iter : 4600) loss: 1.4082\n",
      "(iter : 4700) loss: 1.9055\n",
      "(iter : 4800) loss: 1.4462\n",
      "(iter : 4900) loss: 1.4665\n",
      "(iter : 5000) loss: 1.3094\n",
      "(iter : 5100) loss: 1.3912\n",
      "(iter : 5200) loss: 1.8213\n",
      "(iter : 5300) loss: 1.3279\n",
      "(iter : 5400) loss: 1.5035\n",
      "(iter : 5500) loss: 1.3442\n",
      "(iter : 5600) loss: 1.0651\n",
      "(iter : 5700) loss: 1.2707\n",
      "(iter : 5800) loss: 1.1866\n",
      "(iter : 5900) loss: 1.1781\n",
      "(iter : 6000) loss: 1.2999\n",
      "(iter : 6100) loss: 1.1348\n",
      "(iter : 6200) loss: 1.2145\n",
      "(iter : 6300) loss: 1.2183\n",
      "(iter : 6400) loss: 0.8832\n",
      "(iter : 6500) loss: 1.0745\n",
      "(iter : 6600) loss: 0.9165\n",
      "(iter : 6700) loss: 0.9771\n",
      "(iter : 6800) loss: 0.8618\n",
      "(iter : 6900) loss: 1.1411\n",
      "(iter : 7000) loss: 1.1680\n",
      "(iter : 7100) loss: 0.9333\n",
      "(iter : 7200) loss: 1.1332\n",
      "(iter : 7300) loss: 1.2075\n",
      "(iter : 7400) loss: 0.9035\n",
      "(iter : 7500) loss: 1.1012\n",
      "(iter : 7600) loss: 0.9347\n",
      "(iter : 7700) loss: 0.9711\n",
      "(iter : 7800) loss: 0.8871\n",
      "(iter : 7900) loss: 0.6972\n",
      "(iter : 8000) loss: 1.0653\n",
      "(iter : 8100) loss: 1.1076\n",
      "(iter : 8200) loss: 1.0126\n",
      "(iter : 8300) loss: 1.2713\n",
      "(iter : 8400) loss: 0.7382\n",
      "(iter : 8500) loss: 0.9904\n",
      "(iter : 8600) loss: 0.6247\n",
      "(iter : 8700) loss: 0.9255\n",
      "(iter : 8800) loss: 0.9144\n",
      "(iter : 8900) loss: 0.6638\n",
      "(iter : 9000) loss: 0.6756\n",
      "(iter : 9100) loss: 0.8296\n",
      "(iter : 9200) loss: 0.8770\n",
      "(iter : 9300) loss: 0.8380\n",
      "(iter : 9400) loss: 0.5374\n",
      "(iter : 9500) loss: 0.9579\n",
      "(iter : 9600) loss: 0.7321\n",
      "(iter : 9700) loss: 1.0112\n",
      "(iter : 9800) loss: 1.0002\n",
      "(iter : 9900) loss: 0.6610\n",
      "(iter : 10000) loss: 0.6430\n",
      "learning rate is decayed! current lr :  0.005\n",
      "model is saved!\n",
      "(iter : 10100) loss: 0.4573\n",
      "(iter : 10200) loss: 0.3157\n",
      "(iter : 10300) loss: 0.2486\n",
      "(iter : 10400) loss: 0.3538\n",
      "(iter : 10500) loss: 0.3285\n",
      "(iter : 10600) loss: 0.3185\n",
      "(iter : 10700) loss: 0.3736\n",
      "(iter : 10800) loss: 0.1702\n",
      "(iter : 10900) loss: 0.2860\n",
      "(iter : 11000) loss: 0.3187\n",
      "(iter : 11100) loss: 0.2671\n",
      "(iter : 11200) loss: 0.3115\n",
      "(iter : 11300) loss: 0.3393\n",
      "(iter : 11400) loss: 0.2521\n",
      "(iter : 11500) loss: 0.3206\n",
      "(iter : 11600) loss: 0.3649\n",
      "(iter : 11700) loss: 0.4235\n",
      "(iter : 11800) loss: 0.3512\n",
      "(iter : 11900) loss: 0.4912\n",
      "(iter : 12000) loss: 0.3142\n",
      "(iter : 12100) loss: 0.2872\n",
      "(iter : 12200) loss: 0.1937\n",
      "(iter : 12300) loss: 0.4205\n",
      "(iter : 12400) loss: 0.2693\n",
      "(iter : 12500) loss: 0.3533\n",
      "(iter : 12600) loss: 0.3274\n",
      "(iter : 12700) loss: 0.3964\n",
      "(iter : 12800) loss: 0.2518\n",
      "(iter : 12900) loss: 0.1595\n",
      "(iter : 13000) loss: 0.4027\n",
      "(iter : 13100) loss: 0.2250\n",
      "(iter : 13200) loss: 0.2567\n",
      "(iter : 13300) loss: 0.4587\n",
      "(iter : 13400) loss: 0.3797\n",
      "(iter : 13500) loss: 0.1960\n",
      "(iter : 13600) loss: 0.4283\n",
      "(iter : 13700) loss: 0.3890\n",
      "(iter : 13800) loss: 0.2669\n",
      "(iter : 13900) loss: 0.2986\n",
      "(iter : 14000) loss: 0.4009\n",
      "(iter : 14100) loss: 0.1824\n",
      "(iter : 14200) loss: 0.3952\n",
      "(iter : 14300) loss: 0.3251\n",
      "(iter : 14400) loss: 0.1558\n",
      "(iter : 14500) loss: 0.5953\n",
      "(iter : 14600) loss: 0.3317\n",
      "(iter : 14700) loss: 0.1853\n",
      "(iter : 14800) loss: 0.1491\n",
      "(iter : 14900) loss: 0.3773\n",
      "(iter : 15000) loss: 0.1298\n",
      "(iter : 15100) loss: 0.2855\n",
      "(iter : 15200) loss: 0.2972\n",
      "(iter : 15300) loss: 0.1174\n",
      "(iter : 15400) loss: 0.3207\n",
      "(iter : 15500) loss: 0.1161\n",
      "(iter : 15600) loss: 0.1876\n",
      "(iter : 15700) loss: 0.2734\n",
      "(iter : 15800) loss: 0.3048\n",
      "(iter : 15900) loss: 0.3774\n",
      "(iter : 16000) loss: 0.1931\n",
      "(iter : 16100) loss: 0.2487\n",
      "(iter : 16200) loss: 0.2244\n",
      "(iter : 16300) loss: 0.3594\n",
      "(iter : 16400) loss: 0.1757\n",
      "(iter : 16500) loss: 0.1114\n",
      "(iter : 16600) loss: 0.2249\n",
      "(iter : 16700) loss: 0.3161\n",
      "(iter : 16800) loss: 0.2188\n",
      "(iter : 16900) loss: 0.2667\n",
      "(iter : 17000) loss: 0.3078\n",
      "(iter : 17100) loss: 0.1809\n",
      "(iter : 17200) loss: 0.1908\n",
      "(iter : 17300) loss: 0.2539\n",
      "(iter : 17400) loss: 0.2138\n",
      "(iter : 17500) loss: 0.2115\n",
      "(iter : 17600) loss: 0.1854\n",
      "(iter : 17700) loss: 0.2970\n",
      "(iter : 17800) loss: 0.1249\n",
      "(iter : 17900) loss: 0.1627\n",
      "(iter : 18000) loss: 0.3547\n",
      "(iter : 18100) loss: 0.1944\n",
      "(iter : 18200) loss: 0.2034\n",
      "(iter : 18300) loss: 0.1581\n",
      "(iter : 18400) loss: 0.2367\n",
      "(iter : 18500) loss: 0.2507\n",
      "(iter : 18600) loss: 0.3547\n",
      "(iter : 18700) loss: 0.0963\n",
      "(iter : 18800) loss: 0.2386\n",
      "(iter : 18900) loss: 0.1412\n",
      "(iter : 19000) loss: 0.3365\n",
      "(iter : 19100) loss: 0.2723\n",
      "(iter : 19200) loss: 0.1802\n",
      "(iter : 19300) loss: 0.2264\n",
      "(iter : 19400) loss: 0.2802\n",
      "(iter : 19500) loss: 0.3086\n",
      "(iter : 19600) loss: 0.1142\n",
      "(iter : 19700) loss: 0.3499\n",
      "(iter : 19800) loss: 0.1863\n",
      "(iter : 19900) loss: 0.1070\n",
      "(iter : 20000) loss: 0.1462\n",
      "learning rate is decayed! current lr :  0.0025\n",
      "model is saved!\n",
      "(iter : 20100) loss: 0.0974\n",
      "(iter : 20200) loss: 0.0525\n",
      "(iter : 20300) loss: 0.0813\n",
      "(iter : 20400) loss: 0.0928\n",
      "(iter : 20500) loss: 0.1587\n",
      "(iter : 20600) loss: 0.0513\n",
      "(iter : 20700) loss: 0.1531\n",
      "(iter : 20800) loss: 0.0854\n",
      "(iter : 20900) loss: 0.0940\n",
      "(iter : 21000) loss: 0.1410\n",
      "(iter : 21100) loss: 0.1399\n",
      "(iter : 21200) loss: 0.0155\n",
      "(iter : 21300) loss: 0.0721\n",
      "(iter : 21400) loss: 0.0794\n",
      "(iter : 21500) loss: 0.1081\n",
      "(iter : 21600) loss: 0.0377\n",
      "(iter : 21700) loss: 0.0723\n",
      "(iter : 21800) loss: 0.1136\n",
      "(iter : 21900) loss: 0.0226\n",
      "(iter : 22000) loss: 0.0326\n",
      "(iter : 22100) loss: 0.0639\n",
      "(iter : 22200) loss: 0.0786\n",
      "(iter : 22300) loss: 0.0695\n",
      "(iter : 22400) loss: 0.1294\n",
      "(iter : 22500) loss: 0.1040\n",
      "(iter : 22600) loss: 0.1441\n",
      "(iter : 22700) loss: 0.1499\n",
      "(iter : 22800) loss: 0.0904\n",
      "(iter : 22900) loss: 0.1103\n",
      "(iter : 23000) loss: 0.0727\n",
      "(iter : 23100) loss: 0.0755\n",
      "(iter : 23200) loss: 0.0732\n",
      "(iter : 23300) loss: 0.0903\n",
      "(iter : 23400) loss: 0.0508\n",
      "(iter : 23500) loss: 0.1153\n",
      "(iter : 23600) loss: 0.2251\n",
      "(iter : 23700) loss: 0.1097\n",
      "(iter : 23800) loss: 0.0714\n",
      "(iter : 23900) loss: 0.1126\n",
      "(iter : 24000) loss: 0.0847\n",
      "(iter : 24100) loss: 0.0749\n",
      "(iter : 24200) loss: 0.0897\n",
      "(iter : 24300) loss: 0.1600\n",
      "(iter : 24400) loss: 0.0389\n",
      "(iter : 24500) loss: 0.1594\n",
      "(iter : 24600) loss: 0.0870\n",
      "(iter : 24700) loss: 0.1017\n",
      "(iter : 24800) loss: 0.0836\n",
      "(iter : 24900) loss: 0.0203\n",
      "(iter : 25000) loss: 0.0703\n",
      "(iter : 25100) loss: 0.0381\n",
      "(iter : 25200) loss: 0.1418\n",
      "(iter : 25300) loss: 0.1230\n",
      "(iter : 25400) loss: 0.0636\n",
      "(iter : 25500) loss: 0.1071\n",
      "(iter : 25600) loss: 0.1101\n",
      "(iter : 25700) loss: 0.0815\n",
      "(iter : 25800) loss: 0.0500\n",
      "(iter : 25900) loss: 0.0340\n",
      "(iter : 26000) loss: 0.1151\n",
      "(iter : 26100) loss: 0.0422\n",
      "(iter : 26200) loss: 0.0590\n",
      "(iter : 26300) loss: 0.1058\n",
      "(iter : 26400) loss: 0.0655\n",
      "(iter : 26500) loss: 0.1449\n",
      "(iter : 26600) loss: 0.0472\n",
      "(iter : 26700) loss: 0.0166\n",
      "(iter : 26800) loss: 0.0680\n",
      "(iter : 26900) loss: 0.0639\n",
      "(iter : 27000) loss: 0.0532\n",
      "(iter : 27100) loss: 0.0660\n",
      "(iter : 27200) loss: 0.1735\n",
      "(iter : 27300) loss: 0.0634\n",
      "(iter : 27400) loss: 0.0279\n",
      "(iter : 27500) loss: 0.0180\n",
      "(iter : 27600) loss: 0.0797\n",
      "(iter : 27700) loss: 0.0344\n",
      "(iter : 27800) loss: 0.0415\n",
      "(iter : 27900) loss: 0.0200\n",
      "(iter : 28000) loss: 0.0751\n",
      "(iter : 28100) loss: 0.1368\n",
      "(iter : 28200) loss: 0.0890\n",
      "(iter : 28300) loss: 0.0878\n",
      "(iter : 28400) loss: 0.0276\n",
      "(iter : 28500) loss: 0.0691\n",
      "(iter : 28600) loss: 0.0784\n",
      "(iter : 28700) loss: 0.0343\n",
      "(iter : 28800) loss: 0.0581\n",
      "(iter : 28900) loss: 0.1370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iter : 29000) loss: 0.0863\n",
      "(iter : 29100) loss: 0.1497\n",
      "(iter : 29200) loss: 0.0167\n",
      "(iter : 29300) loss: 0.0961\n",
      "(iter : 29400) loss: 0.0541\n",
      "(iter : 29500) loss: 0.0882\n",
      "(iter : 29600) loss: 0.1595\n",
      "(iter : 29700) loss: 0.0418\n",
      "(iter : 29800) loss: 0.0796\n",
      "(iter : 29900) loss: 0.1537\n",
      "(iter : 30000) loss: 0.0747\n",
      "learning rate is decayed! current lr :  0.00125\n",
      "model is saved!\n",
      "(iter : 30100) loss: 0.0533\n",
      "(iter : 30200) loss: 0.0157\n",
      "(iter : 30300) loss: 0.0112\n",
      "(iter : 30400) loss: 0.0237\n",
      "(iter : 30500) loss: 0.0596\n",
      "(iter : 30600) loss: 0.0269\n",
      "(iter : 30700) loss: 0.0422\n",
      "(iter : 30800) loss: 0.0738\n",
      "(iter : 30900) loss: 0.0472\n",
      "(iter : 31000) loss: 0.0289\n",
      "(iter : 31100) loss: 0.0354\n",
      "(iter : 31200) loss: 0.0859\n",
      "(iter : 31300) loss: 0.0640\n",
      "(iter : 31400) loss: 0.0259\n",
      "(iter : 31500) loss: 0.0133\n",
      "(iter : 31600) loss: 0.1477\n",
      "(iter : 31700) loss: 0.0302\n",
      "(iter : 31800) loss: 0.0094\n",
      "(iter : 31900) loss: 0.0254\n",
      "(iter : 32000) loss: 0.0782\n",
      "(iter : 32100) loss: 0.0444\n",
      "(iter : 32200) loss: 0.0518\n",
      "(iter : 32300) loss: 0.0667\n",
      "(iter : 32400) loss: 0.0343\n",
      "(iter : 32500) loss: 0.0090\n",
      "(iter : 32600) loss: 0.0188\n",
      "(iter : 32700) loss: 0.0125\n",
      "(iter : 32800) loss: 0.0581\n",
      "(iter : 32900) loss: 0.0308\n",
      "(iter : 33000) loss: 0.0617\n",
      "(iter : 33100) loss: 0.0793\n",
      "(iter : 33200) loss: 0.0661\n",
      "(iter : 33300) loss: 0.0519\n",
      "(iter : 33400) loss: 0.0917\n",
      "(iter : 33500) loss: 0.0197\n",
      "(iter : 33600) loss: 0.0231\n",
      "(iter : 33700) loss: 0.0219\n",
      "(iter : 33800) loss: 0.0661\n",
      "(iter : 33900) loss: 0.0088\n",
      "(iter : 34000) loss: 0.0792\n",
      "(iter : 34100) loss: 0.0153\n",
      "(iter : 34200) loss: 0.0113\n",
      "(iter : 34300) loss: 0.0125\n",
      "(iter : 34400) loss: 0.0566\n",
      "(iter : 34500) loss: 0.0157\n",
      "(iter : 34600) loss: 0.0120\n",
      "(iter : 34700) loss: 0.0621\n",
      "(iter : 34800) loss: 0.0635\n",
      "(iter : 34900) loss: 0.0391\n",
      "(iter : 35000) loss: 0.0156\n",
      "(iter : 35100) loss: 0.0312\n",
      "(iter : 35200) loss: 0.0127\n",
      "(iter : 35300) loss: 0.0128\n",
      "(iter : 35400) loss: 0.0099\n",
      "(iter : 35500) loss: 0.0269\n",
      "(iter : 35600) loss: 0.0543\n",
      "(iter : 35700) loss: 0.0372\n",
      "(iter : 35800) loss: 0.0710\n",
      "(iter : 35900) loss: 0.0880\n",
      "(iter : 36000) loss: 0.0484\n",
      "(iter : 36100) loss: 0.0586\n",
      "(iter : 36200) loss: 0.0413\n",
      "(iter : 36300) loss: 0.0572\n",
      "(iter : 36400) loss: 0.0329\n",
      "(iter : 36500) loss: 0.0429\n",
      "(iter : 36600) loss: 0.0230\n",
      "(iter : 36700) loss: 0.0488\n",
      "(iter : 36800) loss: 0.0112\n",
      "(iter : 36900) loss: 0.0742\n",
      "(iter : 37000) loss: 0.0336\n",
      "(iter : 37100) loss: 0.0301\n",
      "(iter : 37200) loss: 0.0392\n",
      "(iter : 37300) loss: 0.0085\n",
      "(iter : 37400) loss: 0.0303\n",
      "(iter : 37500) loss: 0.0563\n",
      "(iter : 37600) loss: 0.0710\n",
      "(iter : 37700) loss: 0.0990\n",
      "(iter : 37800) loss: 0.0366\n",
      "(iter : 37900) loss: 0.0088\n",
      "(iter : 38000) loss: 0.0491\n",
      "(iter : 38100) loss: 0.0184\n",
      "(iter : 38200) loss: 0.0259\n",
      "(iter : 38300) loss: 0.0251\n",
      "(iter : 38400) loss: 0.0818\n",
      "(iter : 38500) loss: 0.0098\n",
      "(iter : 38600) loss: 0.0195\n",
      "(iter : 38700) loss: 0.0316\n",
      "(iter : 38800) loss: 0.0754\n",
      "(iter : 38900) loss: 0.0441\n",
      "(iter : 39000) loss: 0.0077\n",
      "(iter : 39100) loss: 0.0294\n",
      "(iter : 39200) loss: 0.0183\n",
      "(iter : 39300) loss: 0.0463\n",
      "(iter : 39400) loss: 0.0803\n",
      "(iter : 39500) loss: 0.0399\n",
      "(iter : 39600) loss: 0.0085\n",
      "(iter : 39700) loss: 0.0598\n",
      "(iter : 39800) loss: 0.0326\n",
      "(iter : 39900) loss: 0.0734\n",
      "(iter : 40000) loss: 0.0142\n",
      "learning rate is decayed! current lr :  0.000625\n",
      "model is saved!\n",
      "(iter : 40100) loss: 0.0348\n",
      "(iter : 40200) loss: 0.0468\n",
      "(iter : 40300) loss: 0.0091\n",
      "(iter : 40400) loss: 0.0199\n",
      "(iter : 40500) loss: 0.0635\n",
      "(iter : 40600) loss: 0.0070\n",
      "(iter : 40700) loss: 0.0340\n",
      "(iter : 40800) loss: 0.0328\n",
      "(iter : 40900) loss: 0.0531\n",
      "(iter : 41000) loss: 0.0143\n",
      "(iter : 41100) loss: 0.0088\n",
      "(iter : 41200) loss: 0.0198\n",
      "(iter : 41300) loss: 0.0170\n",
      "(iter : 41400) loss: 0.1144\n",
      "(iter : 41500) loss: 0.0356\n",
      "(iter : 41600) loss: 0.0325\n",
      "(iter : 41700) loss: 0.0246\n",
      "(iter : 41800) loss: 0.0285\n",
      "(iter : 41900) loss: 0.0090\n",
      "(iter : 42000) loss: 0.0068\n",
      "(iter : 42100) loss: 0.0065\n",
      "(iter : 42200) loss: 0.0451\n",
      "(iter : 42300) loss: 0.0190\n",
      "(iter : 42400) loss: 0.0270\n",
      "(iter : 42500) loss: 0.0718\n",
      "(iter : 42600) loss: 0.0212\n",
      "(iter : 42700) loss: 0.0091\n",
      "(iter : 42800) loss: 0.0064\n",
      "(iter : 42900) loss: 0.0289\n",
      "(iter : 43000) loss: 0.0155\n",
      "(iter : 43100) loss: 0.0120\n",
      "(iter : 43200) loss: 0.0272\n",
      "(iter : 43300) loss: 0.0063\n",
      "(iter : 43400) loss: 0.0184\n",
      "(iter : 43500) loss: 0.0072\n",
      "(iter : 43600) loss: 0.0413\n",
      "(iter : 43700) loss: 0.0074\n",
      "(iter : 43800) loss: 0.0091\n",
      "(iter : 43900) loss: 0.0128\n",
      "(iter : 44000) loss: 0.0252\n",
      "(iter : 44100) loss: 0.0606\n",
      "(iter : 44200) loss: 0.0203\n",
      "(iter : 44300) loss: 0.0064\n",
      "(iter : 44400) loss: 0.0183\n",
      "(iter : 44500) loss: 0.0555\n",
      "(iter : 44600) loss: 0.0671\n",
      "(iter : 44700) loss: 0.0355\n",
      "(iter : 44800) loss: 0.0938\n",
      "(iter : 44900) loss: 0.0234\n",
      "(iter : 45000) loss: 0.0127\n",
      "(iter : 45100) loss: 0.0093\n",
      "(iter : 45200) loss: 0.0101\n",
      "(iter : 45300) loss: 0.0146\n",
      "(iter : 45400) loss: 0.0086\n",
      "(iter : 45500) loss: 0.0390\n",
      "(iter : 45600) loss: 0.0074\n",
      "(iter : 45700) loss: 0.0459\n",
      "(iter : 45800) loss: 0.0071\n",
      "(iter : 45900) loss: 0.0071\n",
      "(iter : 46000) loss: 0.0546\n",
      "(iter : 46100) loss: 0.0675\n",
      "(iter : 46200) loss: 0.0467\n",
      "(iter : 46300) loss: 0.0078\n",
      "(iter : 46400) loss: 0.0063\n",
      "(iter : 46500) loss: 0.0082\n",
      "(iter : 46600) loss: 0.0215\n",
      "(iter : 46700) loss: 0.0061\n",
      "(iter : 46800) loss: 0.0161\n",
      "(iter : 46900) loss: 0.0124\n",
      "(iter : 47000) loss: 0.0131\n",
      "(iter : 47100) loss: 0.0587\n",
      "(iter : 47200) loss: 0.0183\n",
      "(iter : 47300) loss: 0.0155\n",
      "(iter : 47400) loss: 0.0085\n",
      "(iter : 47500) loss: 0.0275\n",
      "(iter : 47600) loss: 0.0124\n",
      "(iter : 47700) loss: 0.0194\n",
      "(iter : 47800) loss: 0.0418\n",
      "(iter : 47900) loss: 0.0095\n",
      "(iter : 48000) loss: 0.0526\n",
      "(iter : 48100) loss: 0.0157\n",
      "(iter : 48200) loss: 0.0162\n",
      "(iter : 48300) loss: 0.0070\n",
      "(iter : 48400) loss: 0.0254\n",
      "(iter : 48500) loss: 0.0198\n",
      "(iter : 48600) loss: 0.0137\n",
      "(iter : 48700) loss: 0.0138\n",
      "(iter : 48800) loss: 0.0067\n",
      "(iter : 48900) loss: 0.0130\n",
      "(iter : 49000) loss: 0.0316\n",
      "(iter : 49100) loss: 0.0105\n",
      "(iter : 49200) loss: 0.0181\n",
      "(iter : 49300) loss: 0.0445\n",
      "(iter : 49400) loss: 0.0531\n",
      "(iter : 49500) loss: 0.0386\n",
      "(iter : 49600) loss: 0.1055\n",
      "(iter : 49700) loss: 0.0082\n",
      "(iter : 49800) loss: 0.0077\n",
      "(iter : 49900) loss: 0.0091\n",
      "(iter : 50000) loss: 0.0163\n",
      "learning rate is decayed! current lr :  0.0003125\n",
      "model is saved!\n",
      "(iter : 50100) loss: 0.0113\n",
      "(iter : 50200) loss: 0.0070\n",
      "(iter : 50300) loss: 0.0321\n",
      "(iter : 50400) loss: 0.0061\n",
      "(iter : 50500) loss: 0.0078\n",
      "(iter : 50600) loss: 0.0558\n",
      "(iter : 50700) loss: 0.0075\n",
      "(iter : 50800) loss: 0.0421\n",
      "(iter : 50900) loss: 0.0238\n",
      "(iter : 51000) loss: 0.0067\n",
      "(iter : 51100) loss: 0.0388\n",
      "(iter : 51200) loss: 0.0300\n",
      "(iter : 51300) loss: 0.0116\n",
      "(iter : 51400) loss: 0.0180\n",
      "(iter : 51500) loss: 0.0628\n",
      "(iter : 51600) loss: 0.0064\n",
      "(iter : 51700) loss: 0.0081\n",
      "(iter : 51800) loss: 0.0647\n",
      "(iter : 51900) loss: 0.0080\n",
      "(iter : 52000) loss: 0.0078\n",
      "(iter : 52100) loss: 0.0083\n",
      "(iter : 52200) loss: 0.0693\n",
      "(iter : 52300) loss: 0.0267\n",
      "(iter : 52400) loss: 0.0102\n",
      "(iter : 52500) loss: 0.0542\n",
      "(iter : 52600) loss: 0.0078\n",
      "(iter : 52700) loss: 0.0068\n",
      "(iter : 52800) loss: 0.0244\n",
      "(iter : 52900) loss: 0.0116\n",
      "(iter : 53000) loss: 0.0481\n",
      "(iter : 53100) loss: 0.0792\n",
      "(iter : 53200) loss: 0.0226\n",
      "(iter : 53300) loss: 0.0200\n",
      "(iter : 53400) loss: 0.0111\n",
      "(iter : 53500) loss: 0.0066\n",
      "(iter : 53600) loss: 0.0093\n",
      "(iter : 53700) loss: 0.0072\n",
      "(iter : 53800) loss: 0.0067\n",
      "(iter : 53900) loss: 0.0137\n",
      "(iter : 54000) loss: 0.0234\n",
      "(iter : 54100) loss: 0.0492\n",
      "(iter : 54200) loss: 0.0067\n",
      "(iter : 54300) loss: 0.0176\n",
      "(iter : 54400) loss: 0.0109\n",
      "(iter : 54500) loss: 0.0099\n",
      "(iter : 54600) loss: 0.0064\n",
      "(iter : 54700) loss: 0.0160\n",
      "(iter : 54800) loss: 0.0066\n",
      "(iter : 54900) loss: 0.0094\n",
      "(iter : 55000) loss: 0.0091\n",
      "(iter : 55100) loss: 0.1037\n",
      "(iter : 55200) loss: 0.0055\n",
      "(iter : 55300) loss: 0.0072\n",
      "(iter : 55400) loss: 0.0067\n",
      "(iter : 55500) loss: 0.0275\n",
      "(iter : 55600) loss: 0.0081\n",
      "(iter : 55700) loss: 0.0085\n",
      "(iter : 55800) loss: 0.0065\n",
      "(iter : 55900) loss: 0.0398\n",
      "(iter : 56000) loss: 0.0110\n",
      "(iter : 56100) loss: 0.0697\n",
      "(iter : 56200) loss: 0.0060\n",
      "(iter : 56300) loss: 0.0579\n",
      "(iter : 56400) loss: 0.0136\n",
      "(iter : 56500) loss: 0.0065\n",
      "(iter : 56600) loss: 0.0448\n",
      "(iter : 56700) loss: 0.0081\n",
      "(iter : 56800) loss: 0.0098\n",
      "(iter : 56900) loss: 0.0070\n",
      "(iter : 57000) loss: 0.0061\n",
      "(iter : 57100) loss: 0.0097\n",
      "(iter : 57200) loss: 0.0090\n",
      "(iter : 57300) loss: 0.0062\n",
      "(iter : 57400) loss: 0.0100\n",
      "(iter : 57500) loss: 0.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iter : 57600) loss: 0.0087\n",
      "(iter : 57700) loss: 0.0060\n",
      "(iter : 57800) loss: 0.0125\n",
      "(iter : 57900) loss: 0.0091\n",
      "(iter : 58000) loss: 0.0201\n",
      "(iter : 58100) loss: 0.0066\n",
      "(iter : 58200) loss: 0.0281\n",
      "(iter : 58300) loss: 0.0059\n",
      "(iter : 58400) loss: 0.0166\n",
      "(iter : 58500) loss: 0.0058\n",
      "(iter : 58600) loss: 0.0101\n",
      "(iter : 58700) loss: 0.0080\n",
      "(iter : 58800) loss: 0.0197\n",
      "(iter : 58900) loss: 0.0062\n",
      "(iter : 59000) loss: 0.0320\n",
      "(iter : 59100) loss: 0.0543\n",
      "(iter : 59200) loss: 0.0132\n",
      "(iter : 59300) loss: 0.0101\n",
      "(iter : 59400) loss: 0.0085\n",
      "(iter : 59500) loss: 0.0522\n",
      "(iter : 59600) loss: 0.0103\n",
      "(iter : 59700) loss: 0.0293\n",
      "(iter : 59800) loss: 0.0092\n",
      "(iter : 59900) loss: 0.0079\n",
      "(iter : 60000) loss: 0.0082\n",
      "learning rate is decayed! current lr :  0.00015625\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "model is saved!\n",
      "(iter : 60100) loss: 0.0158\n",
      "(iter : 60200) loss: 0.0320\n",
      "(iter : 60300) loss: 0.0092\n",
      "(iter : 60400) loss: 0.0063\n",
      "(iter : 60500) loss: 0.0109\n",
      "(iter : 60600) loss: 0.0158\n",
      "(iter : 60700) loss: 0.0086\n",
      "(iter : 60800) loss: 0.0066\n",
      "(iter : 60900) loss: 0.0086\n",
      "(iter : 61000) loss: 0.0119\n",
      "(iter : 61100) loss: 0.0830\n",
      "(iter : 61200) loss: 0.0111\n",
      "(iter : 61300) loss: 0.0371\n",
      "(iter : 61400) loss: 0.0067\n",
      "(iter : 61500) loss: 0.0062\n",
      "(iter : 61600) loss: 0.0083\n",
      "(iter : 61700) loss: 0.0343\n",
      "(iter : 61800) loss: 0.0217\n",
      "(iter : 61900) loss: 0.0112\n",
      "(iter : 62000) loss: 0.0521\n",
      "(iter : 62100) loss: 0.0133\n",
      "(iter : 62200) loss: 0.0058\n",
      "(iter : 62300) loss: 0.0066\n",
      "(iter : 62400) loss: 0.0075\n",
      "(iter : 62500) loss: 0.0781\n",
      "(iter : 62600) loss: 0.0059\n",
      "(iter : 62700) loss: 0.0324\n",
      "(iter : 62800) loss: 0.0059\n",
      "(iter : 62900) loss: 0.0146\n",
      "(iter : 63000) loss: 0.0061\n",
      "(iter : 63100) loss: 0.0074\n",
      "(iter : 63200) loss: 0.0094\n",
      "(iter : 63300) loss: 0.0071\n",
      "(iter : 63400) loss: 0.0524\n",
      "(iter : 63500) loss: 0.0066\n",
      "(iter : 63600) loss: 0.0056\n",
      "(iter : 63700) loss: 0.0059\n",
      "(iter : 63800) loss: 0.0078\n",
      "(iter : 63900) loss: 0.0065\n",
      "(iter : 64000) loss: 0.0062\n",
      "(iter : 64100) loss: 0.0075\n",
      "(iter : 64200) loss: 0.0066\n",
      "(iter : 64300) loss: 0.0196\n",
      "(iter : 64400) loss: 0.0066\n",
      "(iter : 64500) loss: 0.0243\n",
      "(iter : 64600) loss: 0.0083\n",
      "(iter : 64700) loss: 0.0433\n",
      "(iter : 64800) loss: 0.0214\n",
      "(iter : 64900) loss: 0.0071\n",
      "(iter : 65000) loss: 0.0076\n",
      "(iter : 65100) loss: 0.0084\n",
      "(iter : 65200) loss: 0.0074\n",
      "(iter : 65300) loss: 0.0060\n",
      "(iter : 65400) loss: 0.0126\n",
      "(iter : 65500) loss: 0.0104\n",
      "(iter : 65600) loss: 0.0077\n",
      "(iter : 65700) loss: 0.0081\n",
      "(iter : 65800) loss: 0.0438\n",
      "(iter : 65900) loss: 0.0066\n",
      "(iter : 66000) loss: 0.0087\n",
      "(iter : 66100) loss: 0.0061\n",
      "(iter : 66200) loss: 0.0075\n",
      "(iter : 66300) loss: 0.0096\n",
      "(iter : 66400) loss: 0.0084\n",
      "(iter : 66500) loss: 0.0199\n",
      "(iter : 66600) loss: 0.0067\n",
      "(iter : 66700) loss: 0.0097\n",
      "(iter : 66800) loss: 0.0568\n",
      "(iter : 66900) loss: 0.0142\n",
      "(iter : 67000) loss: 0.0066\n",
      "(iter : 67100) loss: 0.0095\n",
      "(iter : 67200) loss: 0.0180\n",
      "(iter : 67300) loss: 0.0061\n",
      "(iter : 67400) loss: 0.0059\n",
      "(iter : 67500) loss: 0.0134\n",
      "(iter : 67600) loss: 0.0067\n",
      "(iter : 67700) loss: 0.0461\n",
      "(iter : 67800) loss: 0.0073\n",
      "(iter : 67900) loss: 0.0069\n",
      "(iter : 68000) loss: 0.0054\n",
      "(iter : 68100) loss: 0.0070\n",
      "(iter : 68200) loss: 0.0061\n",
      "(iter : 68300) loss: 0.0090\n",
      "(iter : 68400) loss: 0.0064\n",
      "(iter : 68500) loss: 0.0063\n",
      "(iter : 68600) loss: 0.0227\n",
      "(iter : 68700) loss: 0.0057\n",
      "(iter : 68800) loss: 0.0062\n",
      "(iter : 68900) loss: 0.0087\n",
      "(iter : 69000) loss: 0.0062\n",
      "(iter : 69100) loss: 0.0351\n",
      "(iter : 69200) loss: 0.0090\n",
      "(iter : 69300) loss: 0.0124\n",
      "(iter : 69400) loss: 0.0066\n",
      "(iter : 69500) loss: 0.0078\n",
      "(iter : 69600) loss: 0.0054\n",
      "(iter : 69700) loss: 0.0075\n",
      "(iter : 69800) loss: 0.0070\n",
      "(iter : 69900) loss: 0.0087\n",
      "(iter : 70000) loss: 0.0067\n",
      "learning rate is decayed! current lr :  7.8125e-05\n",
      "model is saved!\n",
      "(iter : 70100) loss: 0.0073\n",
      "(iter : 70200) loss: 0.0056\n",
      "(iter : 70300) loss: 0.0092\n",
      "(iter : 70400) loss: 0.0468\n",
      "(iter : 70500) loss: 0.0111\n",
      "(iter : 70600) loss: 0.0170\n",
      "(iter : 70700) loss: 0.0057\n",
      "(iter : 70800) loss: 0.0111\n",
      "(iter : 70900) loss: 0.0120\n",
      "(iter : 71000) loss: 0.0065\n",
      "(iter : 71100) loss: 0.0091\n",
      "(iter : 71200) loss: 0.0092\n",
      "(iter : 71300) loss: 0.0321\n",
      "(iter : 71400) loss: 0.0055\n",
      "(iter : 71500) loss: 0.0069\n",
      "(iter : 71600) loss: 0.0104\n",
      "(iter : 71700) loss: 0.0094\n",
      "(iter : 71800) loss: 0.0550\n",
      "(iter : 71900) loss: 0.0064\n",
      "(iter : 72000) loss: 0.0078\n",
      "(iter : 72100) loss: 0.0064\n",
      "(iter : 72200) loss: 0.0073\n",
      "(iter : 72300) loss: 0.0060\n",
      "(iter : 72400) loss: 0.0054\n",
      "(iter : 72500) loss: 0.0057\n",
      "(iter : 72600) loss: 0.0105\n",
      "(iter : 72700) loss: 0.0085\n",
      "(iter : 72800) loss: 0.0063\n",
      "(iter : 72900) loss: 0.0075\n",
      "(iter : 73000) loss: 0.0058\n",
      "(iter : 73100) loss: 0.0056\n",
      "(iter : 73200) loss: 0.0066\n",
      "(iter : 73300) loss: 0.0079\n",
      "(iter : 73400) loss: 0.0062\n",
      "(iter : 73500) loss: 0.0061\n",
      "(iter : 73600) loss: 0.0133\n",
      "(iter : 73700) loss: 0.0054\n",
      "(iter : 73800) loss: 0.0101\n",
      "(iter : 73900) loss: 0.0090\n",
      "(iter : 74000) loss: 0.0065\n",
      "(iter : 74100) loss: 0.0076\n",
      "(iter : 74200) loss: 0.0629\n",
      "(iter : 74300) loss: 0.0080\n",
      "(iter : 74400) loss: 0.0513\n",
      "(iter : 74500) loss: 0.0078\n",
      "(iter : 74600) loss: 0.0285\n",
      "(iter : 74700) loss: 0.0658\n",
      "(iter : 74800) loss: 0.0092\n",
      "(iter : 74900) loss: 0.0145\n",
      "(iter : 75000) loss: 0.0689\n",
      "(iter : 75100) loss: 0.0083\n",
      "(iter : 75200) loss: 0.1079\n",
      "(iter : 75300) loss: 0.0065\n",
      "(iter : 75400) loss: 0.0196\n",
      "(iter : 75500) loss: 0.0076\n",
      "(iter : 75600) loss: 0.0255\n",
      "(iter : 75700) loss: 0.0075\n",
      "(iter : 75800) loss: 0.0075\n",
      "(iter : 75900) loss: 0.0066\n",
      "(iter : 76000) loss: 0.0057\n",
      "(iter : 76100) loss: 0.0066\n",
      "(iter : 76200) loss: 0.0081\n",
      "(iter : 76300) loss: 0.0077\n",
      "(iter : 76400) loss: 0.0087\n",
      "(iter : 76500) loss: 0.0060\n",
      "(iter : 76600) loss: 0.0627\n",
      "(iter : 76700) loss: 0.0054\n",
      "(iter : 76800) loss: 0.0680\n",
      "(iter : 76900) loss: 0.0073\n",
      "(iter : 77000) loss: 0.0069\n",
      "(iter : 77100) loss: 0.0069\n",
      "(iter : 77200) loss: 0.0326\n",
      "(iter : 77300) loss: 0.0194\n",
      "(iter : 77400) loss: 0.0057\n",
      "(iter : 77500) loss: 0.0072\n",
      "(iter : 77600) loss: 0.0542\n",
      "(iter : 77700) loss: 0.0108\n",
      "(iter : 77800) loss: 0.0070\n",
      "(iter : 77900) loss: 0.0062\n",
      "(iter : 78000) loss: 0.0072\n",
      "(iter : 78100) loss: 0.0091\n",
      "(iter : 78200) loss: 0.0055\n",
      "(iter : 78300) loss: 0.0059\n",
      "(iter : 78400) loss: 0.0154\n",
      "(iter : 78500) loss: 0.0087\n",
      "(iter : 78600) loss: 0.0059\n",
      "(iter : 78700) loss: 0.0084\n",
      "(iter : 78800) loss: 0.0063\n",
      "(iter : 78900) loss: 0.0107\n",
      "(iter : 79000) loss: 0.0079\n",
      "(iter : 79100) loss: 0.0074\n",
      "(iter : 79200) loss: 0.0058\n",
      "(iter : 79300) loss: 0.0300\n",
      "(iter : 79400) loss: 0.0078\n",
      "(iter : 79500) loss: 0.0102\n",
      "(iter : 79600) loss: 0.0062\n",
      "(iter : 79700) loss: 0.0068\n",
      "(iter : 79800) loss: 0.0072\n",
      "(iter : 79900) loss: 0.0228\n",
      "(iter : 80000) loss: 0.0222\n",
      "learning rate is decayed! current lr :  3.90625e-05\n",
      "model is saved!\n",
      "(iter : 80100) loss: 0.0627\n",
      "(iter : 80200) loss: 0.0176\n",
      "(iter : 80300) loss: 0.0163\n",
      "(iter : 80400) loss: 0.0082\n",
      "(iter : 80500) loss: 0.0080\n",
      "(iter : 80600) loss: 0.0057\n",
      "(iter : 80700) loss: 0.0136\n",
      "(iter : 80800) loss: 0.0062\n",
      "(iter : 80900) loss: 0.0054\n",
      "(iter : 81000) loss: 0.0057\n",
      "(iter : 81100) loss: 0.0083\n",
      "(iter : 81200) loss: 0.0077\n",
      "(iter : 81300) loss: 0.0054\n",
      "(iter : 81400) loss: 0.0076\n",
      "(iter : 81500) loss: 0.0064\n",
      "(iter : 81600) loss: 0.0091\n",
      "(iter : 81700) loss: 0.0086\n",
      "(iter : 81800) loss: 0.0068\n",
      "(iter : 81900) loss: 0.0053\n",
      "(iter : 82000) loss: 0.0095\n",
      "(iter : 82100) loss: 0.0070\n",
      "(iter : 82200) loss: 0.0060\n",
      "(iter : 82300) loss: 0.0139\n",
      "(iter : 82400) loss: 0.0097\n",
      "(iter : 82500) loss: 0.0214\n",
      "(iter : 82600) loss: 0.0057\n",
      "(iter : 82700) loss: 0.0066\n",
      "(iter : 82800) loss: 0.0063\n",
      "(iter : 82900) loss: 0.0404\n",
      "(iter : 83000) loss: 0.0062\n",
      "(iter : 83100) loss: 0.0054\n",
      "(iter : 83200) loss: 0.0094\n",
      "(iter : 83300) loss: 0.0100\n",
      "(iter : 83400) loss: 0.0057\n",
      "(iter : 83500) loss: 0.0096\n",
      "(iter : 83600) loss: 0.0082\n",
      "(iter : 83700) loss: 0.0064\n",
      "(iter : 83800) loss: 0.0123\n",
      "(iter : 83900) loss: 0.0059\n",
      "(iter : 84000) loss: 0.0357\n",
      "(iter : 84100) loss: 0.0074\n",
      "(iter : 84200) loss: 0.0569\n",
      "(iter : 84300) loss: 0.0064\n",
      "(iter : 84400) loss: 0.0066\n",
      "(iter : 84500) loss: 0.0338\n",
      "(iter : 84600) loss: 0.0060\n",
      "(iter : 84700) loss: 0.0059\n",
      "(iter : 84800) loss: 0.0109\n",
      "(iter : 84900) loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iter : 85000) loss: 0.0058\n",
      "(iter : 85100) loss: 0.0056\n",
      "(iter : 85200) loss: 0.0337\n",
      "(iter : 85300) loss: 0.0061\n",
      "(iter : 85400) loss: 0.0061\n",
      "(iter : 85500) loss: 0.0233\n",
      "(iter : 85600) loss: 0.0073\n",
      "(iter : 85700) loss: 0.0095\n",
      "(iter : 85800) loss: 0.0057\n",
      "(iter : 85900) loss: 0.0055\n",
      "(iter : 86000) loss: 0.0072\n",
      "(iter : 86100) loss: 0.0059\n",
      "(iter : 86200) loss: 0.0063\n",
      "(iter : 86300) loss: 0.0062\n",
      "(iter : 86400) loss: 0.0100\n",
      "(iter : 86500) loss: 0.0093\n",
      "(iter : 86600) loss: 0.0362\n",
      "(iter : 86700) loss: 0.0054\n",
      "(iter : 86800) loss: 0.0056\n",
      "(iter : 86900) loss: 0.0053\n",
      "(iter : 87000) loss: 0.0059\n",
      "(iter : 87100) loss: 0.0087\n",
      "(iter : 87200) loss: 0.0068\n",
      "(iter : 87300) loss: 0.0088\n",
      "(iter : 87400) loss: 0.0062\n",
      "(iter : 87500) loss: 0.0235\n",
      "(iter : 87600) loss: 0.0668\n",
      "(iter : 87700) loss: 0.0091\n",
      "(iter : 87800) loss: 0.0061\n",
      "(iter : 87900) loss: 0.0060\n",
      "(iter : 88000) loss: 0.0063\n",
      "(iter : 88100) loss: 0.0056\n",
      "(iter : 88200) loss: 0.0058\n",
      "(iter : 88300) loss: 0.0188\n",
      "(iter : 88400) loss: 0.0138\n",
      "(iter : 88500) loss: 0.0074\n",
      "(iter : 88600) loss: 0.0058\n",
      "(iter : 88700) loss: 0.0129\n",
      "(iter : 88800) loss: 0.0063\n",
      "(iter : 88900) loss: 0.0057\n",
      "(iter : 89000) loss: 0.0092\n",
      "(iter : 89100) loss: 0.0100\n",
      "(iter : 89200) loss: 0.0481\n",
      "(iter : 89300) loss: 0.0057\n",
      "(iter : 89400) loss: 0.0357\n",
      "(iter : 89500) loss: 0.0205\n",
      "(iter : 89600) loss: 0.0083\n",
      "(iter : 89700) loss: 0.0063\n",
      "(iter : 89800) loss: 0.0252\n",
      "(iter : 89900) loss: 0.0557\n",
      "(iter : 90000) loss: 0.0629\n",
      "learning rate is decayed! current lr :  1.953125e-05\n",
      "model is saved!\n",
      "(iter : 90100) loss: 0.0061\n",
      "(iter : 90200) loss: 0.0070\n",
      "(iter : 90300) loss: 0.0099\n",
      "(iter : 90400) loss: 0.0060\n",
      "(iter : 90500) loss: 0.0081\n",
      "(iter : 90600) loss: 0.0277\n",
      "(iter : 90700) loss: 0.0100\n",
      "(iter : 90800) loss: 0.0067\n",
      "(iter : 90900) loss: 0.0065\n",
      "(iter : 91000) loss: 0.0168\n",
      "(iter : 91100) loss: 0.0077\n",
      "(iter : 91200) loss: 0.0056\n",
      "(iter : 91300) loss: 0.0083\n",
      "(iter : 91400) loss: 0.0083\n",
      "(iter : 91500) loss: 0.0106\n",
      "(iter : 91600) loss: 0.0286\n",
      "(iter : 91700) loss: 0.0053\n",
      "(iter : 91800) loss: 0.0069\n",
      "(iter : 91900) loss: 0.0060\n",
      "(iter : 92000) loss: 0.0073\n",
      "(iter : 92100) loss: 0.0066\n",
      "(iter : 92200) loss: 0.0107\n",
      "(iter : 92300) loss: 0.0065\n",
      "(iter : 92400) loss: 0.0063\n",
      "(iter : 92500) loss: 0.0054\n",
      "(iter : 92600) loss: 0.0079\n",
      "(iter : 92700) loss: 0.0271\n",
      "(iter : 92800) loss: 0.0058\n",
      "(iter : 92900) loss: 0.0055\n",
      "(iter : 93000) loss: 0.0086\n",
      "(iter : 93100) loss: 0.0069\n",
      "(iter : 93200) loss: 0.0072\n",
      "(iter : 93300) loss: 0.0101\n",
      "(iter : 93400) loss: 0.0062\n",
      "(iter : 93500) loss: 0.0068\n",
      "(iter : 93600) loss: 0.0128\n",
      "(iter : 93700) loss: 0.0065\n",
      "(iter : 93800) loss: 0.0572\n",
      "(iter : 93900) loss: 0.0066\n",
      "(iter : 94000) loss: 0.0350\n",
      "(iter : 94100) loss: 0.0061\n",
      "(iter : 94200) loss: 0.0057\n",
      "(iter : 94300) loss: 0.0061\n",
      "(iter : 94400) loss: 0.0060\n",
      "(iter : 94500) loss: 0.0069\n",
      "(iter : 94600) loss: 0.0223\n",
      "(iter : 94700) loss: 0.0113\n",
      "(iter : 94800) loss: 0.0071\n",
      "(iter : 94900) loss: 0.0110\n",
      "(iter : 95000) loss: 0.0058\n",
      "(iter : 95100) loss: 0.0061\n",
      "(iter : 95200) loss: 0.0061\n",
      "(iter : 95300) loss: 0.0089\n",
      "(iter : 95400) loss: 0.0054\n",
      "(iter : 95500) loss: 0.0173\n",
      "(iter : 95600) loss: 0.0437\n",
      "(iter : 95700) loss: 0.0078\n",
      "(iter : 95800) loss: 0.0091\n",
      "(iter : 95900) loss: 0.0065\n",
      "(iter : 96000) loss: 0.0063\n",
      "(iter : 96100) loss: 0.0125\n",
      "(iter : 96200) loss: 0.0389\n",
      "(iter : 96300) loss: 0.0098\n",
      "(iter : 96400) loss: 0.0107\n",
      "(iter : 96500) loss: 0.0051\n",
      "(iter : 96600) loss: 0.0497\n",
      "(iter : 96700) loss: 0.0071\n",
      "(iter : 96800) loss: 0.0073\n",
      "(iter : 96900) loss: 0.0079\n",
      "(iter : 97000) loss: 0.0077\n",
      "(iter : 97100) loss: 0.0200\n",
      "(iter : 97200) loss: 0.0448\n",
      "(iter : 97300) loss: 0.0185\n",
      "(iter : 97400) loss: 0.0267\n",
      "(iter : 97500) loss: 0.0789\n",
      "(iter : 97600) loss: 0.0086\n",
      "(iter : 97700) loss: 0.0302\n",
      "(iter : 97800) loss: 0.0069\n",
      "(iter : 97900) loss: 0.0055\n",
      "(iter : 98000) loss: 0.0062\n",
      "(iter : 98100) loss: 0.0132\n",
      "(iter : 98200) loss: 0.0463\n",
      "(iter : 98300) loss: 0.0107\n",
      "(iter : 98400) loss: 0.0337\n",
      "(iter : 98500) loss: 0.0068\n",
      "(iter : 98600) loss: 0.0056\n",
      "(iter : 98700) loss: 0.0063\n",
      "(iter : 98800) loss: 0.0085\n",
      "(iter : 98900) loss: 0.0104\n",
      "(iter : 99000) loss: 0.0057\n",
      "(iter : 99100) loss: 0.0068\n",
      "(iter : 99200) loss: 0.0071\n",
      "(iter : 99300) loss: 0.0107\n",
      "(iter : 99400) loss: 0.0051\n",
      "(iter : 99500) loss: 0.0093\n",
      "(iter : 99600) loss: 0.0089\n",
      "(iter : 99700) loss: 0.0077\n",
      "(iter : 99800) loss: 0.0073\n",
      "(iter : 99900) loss: 0.0150\n",
      "(iter : 100000) loss: 0.0084\n",
      "learning rate is decayed! current lr :  9.765625e-06\n",
      "model is saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from model import train, test\n",
    "from configuration import get_config\n",
    "import errno    \n",
    "import os\n",
    "\n",
    "#RTX float16 setup:\n",
    "tf.compat.v1.keras.backend.set_floatx('float16')\n",
    "tf.compat.v1.keras.backend.set_epsilon(1e-4) \n",
    "\n",
    "config = get_config()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "print(\"\\nTraining Session\")\n",
    "mkdir_p(config.model_path)\n",
    "train(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "Cuda compilation tools, release 10.0, V10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(M=5, N=4, beta1=0.5, beta2=0.9, comment='', hidden=768, hop=0.01, iteration=100000, loss='softmax', lr=0.01, mel_size=80, model_num=6, model_path='./tisv_model', nfft=512, noise_filenum=16, noise_path='./noise', num_layer=3, optim='sgd', proj=256, restore=False, sr=8000, tdsv=False, tdsv_frame=80, test_path='./test_tisv', tisv_frame=180, train=True, train_path='./train_tisv', window=0.025)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"main.py\", line 3, in <module>\r\n",
      "    from model import train, test\r\n",
      "  File \"/tf/notebooks/SKAJPAI/voice_style_transfer/Speaker_Verification/model.py\", line 7, in <module>\r\n",
      "    from tensorflow_addons import rnn\r\n",
      "ModuleNotFoundError: No module named 'tensorflow_addons'\r\n"
     ]
    }
   ],
   "source": [
    "!python3.6 main.py --train=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 817kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow_addons) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.30.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.1.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.24.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.17.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.9.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow_addons) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (41.2.0)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.6.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3.6 -m pip install tensorflow_addons\n",
    "#!apt install libsndfile1 --yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
